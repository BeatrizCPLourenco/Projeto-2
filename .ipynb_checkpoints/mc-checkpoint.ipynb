{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Beatriz Louren√ßo\n",
    "\n",
    "Nome: Gabriel Yamashita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re \n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@Reme72277305***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = \"McDonalds\"\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "# shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa √© manual. Fa√ßa a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"McDonalds.xlsx\",sheet_name = \"Treinamento\")\n",
    "colunas = [\"Treinamento\", \"relevancia\"]\n",
    "data = data.loc[:,colunas]\n",
    "\n",
    "def cleanup(text):\n",
    "    punctuation = \"[!\\-.:?;,'#-]\"\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed    \n",
    "\n",
    "data = cleanup(data.lower())\n",
    "# data_treino = data['Treinamento'].apply(cleanup)\n",
    "\n",
    "# data_treino = pd.Series(data_treino.split())\n",
    "# data_treino\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rel = \" \".join(data[data[\"relevancia\"] == 1].Treinamento)\n",
    "irrel = \" \".join(data[data[\"relevancia\"] == 0].Treinamento)\n",
    "\n",
    "rel = cleanup(rel)\n",
    "irrel = cleanup(irrel)\n",
    "\n",
    "rel = pd.Series(rel.split())\n",
    "irrel = pd.Series(irrel.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@mcdonalds_br       33\n",
       "e                   28\n",
       "de                  27\n",
       "o                   22\n",
       "que                 19\n",
       "no                  19\n",
       "mcdonalds           15\n",
       "do                  15\n",
       "eu                  12\n",
       "@ifood              11\n",
       "n√£o                 11\n",
       "a                   11\n",
       "nunca               10\n",
       "√©                   10\n",
       "um                  10\n",
       "uma                  7\n",
       "tem                  7\n",
       "da                   6\n",
       "//t                  6\n",
       "https                6\n",
       "comer                5\n",
       "s√≥                   5\n",
       "pedido               5\n",
       "pelo                 5\n",
       "pedi                 4\n",
       "mais                 4\n",
       "se                   4\n",
       "esse                 4\n",
       "@samianainternet     4\n",
       "mista                4\n",
       "                    ..\n",
       "devo                 1\n",
       "febre                1\n",
       "üòÇ‚ù§Ô∏è                  1\n",
       "onde                 1\n",
       "preparo              1\n",
       "a√≠                   1\n",
       "meus                 1\n",
       "super                1\n",
       "embu                 1\n",
       "quem                 1\n",
       "papel√£o              1\n",
       "pensar               1\n",
       "imposs√≠vel           1\n",
       "vi                   1\n",
       "ü§¢ü§Æ                   1\n",
       "@ubereats            1\n",
       "monocrom√°tico        1\n",
       "obrigada             1\n",
       "@spencer_rizzuto     1\n",
       "hoje                 1\n",
       "s√≥‚Ä¶                  1\n",
       "zero                 1\n",
       "bk                   1\n",
       "sul                  1\n",
       "tr√™s                 1\n",
       "recifenses           1\n",
       "co/gp7lz30fey        1\n",
       "gra√ßa                1\n",
       "p                    1\n",
       "trabalham            1\n",
       "Length: 400, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_value = rel.value_counts()\n",
    "rel_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mcdonalds         139\n",
       "de                115\n",
       "@mcdonalds_br     101\n",
       "que                82\n",
       "e                  72\n",
       "o                  72\n",
       "do                 71\n",
       "a                  62\n",
       "eu                 61\n",
       "rt                 56\n",
       "//t                56\n",
       "n√£o                56\n",
       "√©                  56\n",
       "https              56\n",
       "no                 54\n",
       "um                 52\n",
       "com                40\n",
       "em                 33\n",
       "uma                29\n",
       "da                 28\n",
       "pra                28\n",
       "por                26\n",
       "na                 24\n",
       "q                  20\n",
       "minha              20\n",
       "voc√™               18\n",
       "2                  18\n",
       "mc                 17\n",
       "se                 17\n",
       "me                 17\n",
       "                 ... \n",
       "dangerous           1\n",
       "facebook)           1\n",
       "trabalha            1\n",
       "inven√ß√£o            1\n",
       "desnecess√°rios      1\n",
       "üôèüèª‚ù§Ô∏èüåπ               1\n",
       "falar               1\n",
       "now                 1\n",
       "@smith_hays         1\n",
       "larson              1\n",
       "ccpc                1\n",
       "facissu             1\n",
       "@gomesataner        1\n",
       "co/em72skimpe       1\n",
       "m√£es                1\n",
       "lei                 1\n",
       "domingo             1\n",
       "@alicelimaa14       1\n",
       "v√°rias              1\n",
       "servir              1\n",
       "parab√©ns            1\n",
       "boneco              1\n",
       "@naty_scabia        1\n",
       "partir              1\n",
       "hashahshhas         1\n",
       "combo               1\n",
       "umali               1\n",
       "pqp                 1\n",
       "harmonia            1\n",
       "@guccifriendss      1\n",
       "Length: 1323, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irrel_value = irrel.value_counts()\n",
    "irrel_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
