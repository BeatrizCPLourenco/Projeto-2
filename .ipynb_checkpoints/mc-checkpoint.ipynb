{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Beatriz Louren√ßo\n",
    "\n",
    "Nome: Gabriel Yamashita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re \n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@Reme72277305***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = \"McDonalds\"\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "# shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa √© manual. Fa√ßa a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"McDonalds.xlsx\",sheet_name = \"Treinamento\")\n",
    "colunas = [\"Treinamento\", \"relevancia\"]\n",
    "data = data.loc[:,colunas]\n",
    "\n",
    "def cleanup(text):\n",
    "    punctuation = \"[!\\-.:?;,'#-@]\"\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed    \n",
    "\n",
    "# data = cleanup(data.lower())\n",
    "# # data_treino = data['Treinamento'].apply(cleanup)\n",
    "\n",
    "# # data_treino = pd.Series(data_treino.split())\n",
    "# # data_treino\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rel = \" \".join(data[data[\"relevancia\"] == 1].Treinamento)\n",
    "irrel = \" \".join(data[data[\"relevancia\"] == 0].Treinamento)\n",
    "\n",
    "rel = cleanup(rel)\n",
    "irrel = cleanup(irrel)\n",
    "\n",
    "rel = pd.Series(rel.split())\n",
    "irrel = pd.Series(irrel.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mcdonalds_br      0.040491\n",
       "e                 0.034356\n",
       "de                0.033129\n",
       "o                 0.026994\n",
       "no                0.023313\n",
       "que               0.023313\n",
       "mcdonalds         0.019632\n",
       "do                0.018405\n",
       "ifood             0.017178\n",
       "eu                0.014724\n",
       "a                 0.014724\n",
       "n√£o               0.013497\n",
       "um                0.012270\n",
       "nunca             0.012270\n",
       "√©                 0.012270\n",
       "uma               0.008589\n",
       "tem               0.008589\n",
       "da                0.007362\n",
       "https             0.007362\n",
       "t                 0.007362\n",
       "co                0.007362\n",
       "pelo              0.006135\n",
       "comer             0.006135\n",
       "s√≥                0.006135\n",
       "pedido            0.006135\n",
       "rt                0.004908\n",
       "pedi              0.004908\n",
       "mista             0.004908\n",
       "se                0.004908\n",
       "mais              0.004908\n",
       "                    ...   \n",
       "vir               0.001227\n",
       "abra√ßo            0.001227\n",
       "hj                0.001227\n",
       "tirado            0.001227\n",
       "üëçüèª                0.001227\n",
       "mec√¥zo            0.001227\n",
       "lojas             0.001227\n",
       "faz               0.001227\n",
       "demorou           0.001227\n",
       "gastei            0.001227\n",
       "hidrogenado       0.001227\n",
       "cupom             0.001227\n",
       "queria            0.001227\n",
       "outro             0.001227\n",
       "beckmannrenata    0.001227\n",
       "caralha           0.001227\n",
       "totem             0.001227\n",
       "manauara          0.001227\n",
       "rua               0.001227\n",
       "lanche            0.001227\n",
       "quer              0.001227\n",
       "eles              0.001227\n",
       "atilevil          0.001227\n",
       "lancheria         0.001227\n",
       "vamo              0.001227\n",
       "paah              0.001227\n",
       "p√©ssimo           0.001227\n",
       "sandu√≠che         0.001227\n",
       "acho              0.001227\n",
       "trabalham         0.001227\n",
       "Length: 400, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_value = rel.value_counts(True)\n",
    "rel_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mcdonalds         0.035303\n",
       "de                0.028193\n",
       "mcdonalds_br      0.025251\n",
       "que               0.020103\n",
       "e                 0.017897\n",
       "o                 0.017651\n",
       "do                0.017406\n",
       "a                 0.015445\n",
       "eu                0.014955\n",
       "t                 0.013974\n",
       "√©                 0.013974\n",
       "co                0.013729\n",
       "n√£o               0.013729\n",
       "https             0.013729\n",
       "rt                0.013729\n",
       "no                0.013239\n",
       "um                0.012748\n",
       "com               0.010051\n",
       "em                0.008581\n",
       "uma               0.007110\n",
       "pra               0.006864\n",
       "da                0.006864\n",
       "por               0.006374\n",
       "na                0.005884\n",
       "q                 0.005393\n",
       "minha             0.004903\n",
       "se                0.004413\n",
       "voc√™              0.004413\n",
       "comer             0.004168\n",
       "me                0.004168\n",
       "                    ...   \n",
       "facissu           0.000245\n",
       "arrependida       0.000245\n",
       "mascote           0.000245\n",
       "trabalha          0.000245\n",
       "bruniin           0.000245\n",
       "inven√ß√£o          0.000245\n",
       "desnecess√°rios    0.000245\n",
       "ss                0.000245\n",
       "fodase            0.000245\n",
       "now               0.000245\n",
       "‚ù§Ô∏è                0.000245\n",
       "larson            0.000245\n",
       "wi                0.000245\n",
       "falar             0.000245\n",
       "sousa_            0.000245\n",
       "lei               0.000245\n",
       "dangerous         0.000245\n",
       "m√£es              0.000245\n",
       "pedromugarte      0.000245\n",
       "v√°rias            0.000245\n",
       "servir            0.000245\n",
       "parab√©ns          0.000245\n",
       "boneco            0.000245\n",
       "partir            0.000245\n",
       "bqquqg            0.000245\n",
       "umali             0.000245\n",
       "jgsjonathan       0.000245\n",
       "pqp               0.000245\n",
       "harmonia          0.000245\n",
       "arielsis          0.000245\n",
       "Length: 1334, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irrel_value = irrel.value_counts(True)\n",
    "irrel_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04049079754601227\n",
      "0.0343558282208589\n",
      "0.033128834355828224\n",
      "0.026993865030674847\n"
     ]
    }
   ],
   "source": [
    "imprime = 4\n",
    "for palavra in rel_value.index:\n",
    "    if imprime:\n",
    "        print(rel_value[palavra])\n",
    "        imprime-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03530277028683501\n",
      "0.028193184604069624\n",
      "0.025251287080166707\n",
      "0.0201029664133366\n"
     ]
    }
   ],
   "source": [
    "imprime = 4\n",
    "for palavra in irrel_value.index:\n",
    "    if imprime:\n",
    "        print(irrel_value[palavra])\n",
    "        imprime-=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
