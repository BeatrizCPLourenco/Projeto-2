{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Beatriz Lourenço\n",
    "\n",
    "Nome: Gabriel Yamashita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import re \n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@Reme72277305***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste projeto buscamos fazer um classificador capaz de detectar os tweets relevantes, ou seja, aqueles que continham opniões negativas da marca escolhida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = \"McDonalds\"\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "# shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Abrindo o Treinamento\n",
    "\n",
    "data = pd.read_excel(\"McDonalds.xlsx\",sheet_name = \"Treinamento\")\n",
    "colunas = [\"Treinamento\", \"relevancia\"]\n",
    "data = data.loc[:,colunas]\n",
    "\n",
    "def cleanup(text):\n",
    "    punctuation = \"[!\\-.:?;,'#-@]\"\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separando em relevantes e irrelevantes e limpando os caracteres irrelevantes\n",
    "\n",
    "rel = \" \".join(data[data[\"relevancia\"] == 1].Treinamento)\n",
    "irrel = \" \".join(data[data[\"relevancia\"] == 0].Treinamento)\n",
    "\n",
    "rel = cleanup(rel)\n",
    "irrel = cleanup(irrel)\n",
    "\n",
    "rel = pd.Series(rel.split())\n",
    "irrel = pd.Series(irrel.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores relativos\n",
    "rel_value = rel.value_counts(True)\n",
    "irrel_value = irrel.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores absolutos\n",
    "rel_value = rel.value_counts()\n",
    "irrel_value = irrel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade de ser relevante e de ser irrelevante\n",
    "\n",
    "n_rel = data[data['relevancia'] == 1].count()\n",
    "n_irrel = data[data['relevancia'] == 0].count()\n",
    "n_total = n_rel + n_irrel\n",
    "prob_rel = n_rel/(n_total)\n",
    "prob_irrel = n_irrel/(n_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-420-3b072e64a46b>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-420-3b072e64a46b>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    prob_p_irrel = prob_p_irrel.sort_values.(ascending=False)\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Laplace Smoothing\n",
    "\n",
    "alpha = 1\n",
    "V = 1e6\n",
    "\n",
    "rel_value_number = rel.value_counts()\n",
    "sum_rel_value_number = rel_value_number.sum()\n",
    "\n",
    "irrel_value_number = irrel.value_counts()\n",
    "sum_irrel_value_number = irrel_value_number.sum()\n",
    "\n",
    "prob_p_rel = (rel_value_number + 1)/(sum_rel_value_number + alpha*V)\n",
    "prob_p_irrel = (irrel_value_number + 1)/(sum_irrel_value_number + alpha*V)\n",
    "\n",
    "prob_p_desc_rel = alpha / (sum_rel_value_number + alpha*V)\n",
    "prob_p_desc_irrel = alpha / (sum_irrel_value_number + alpha*V)\n",
    "\n",
    "prob_p_rel = prob_p_rel.sort_values(ascending=False)\n",
    "prob_p_irrel = prob_p_irrel.sort_values.(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo o Teste\n",
    "\n",
    "data = pd.read_excel(\"McDonalds.xlsx\",sheet_name = \"Teste\")\n",
    "colunas = [\"Teste\", \"relevancia\"]\n",
    "data = data.loc[:,colunas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a chance de ser relevante e irrelevante\n",
    "\n",
    "def classifica_relevante (tweet):\n",
    "    w = cleanup(tweet).split()\n",
    "    prob = np.log(prob_p_rel.reindex(w).fillna(prob_p_desc_rel)).sum()\n",
    "    prob = prob + np.log(prob_rel[0])\n",
    "    return prob\n",
    "data[\"probabilidade relevante\"]=data.Teste.apply(classifica_relevante)\n",
    "data_rel = data[\"probabilidade relevante\"]\n",
    "\n",
    "def classifica_irrelevante (tweet):\n",
    "    w = cleanup(tweet).split()\n",
    "    prob = np.log(prob_p_irrel.reindex(w).fillna(prob_p_desc_irrel)).sum()\n",
    "    prob = prob + np.log(prob_irrel[0])\n",
    "    return prob\n",
    "data[\"probabilidade irrelevante\"]=data.Teste.apply(classifica_irrelevante)\n",
    "data_irrel = data[\"probabilidade irrelevante\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rel = {}\n",
    "Irrel = {}\n",
    "\n",
    "i=0\n",
    "\n",
    "while i <= n-t:\n",
    "    if i['probabilidade_relevante']>i['probabilidade_irrlevante']:\n",
    "        Rel[i['Teste']]=i['probabilidade_relevante']\n",
    "        i+=1\n",
    "    else:\n",
    "        Rel[i['Teste']]=i['probabilidade_irrelevante']\n",
    "        i+=1\n",
    "Rel        \n",
    "\n",
    "# classificados = []\n",
    "# tweet = 0\n",
    "\n",
    "# for tweet in data['Teste']:\n",
    "#     tweet = cleanup(tweet).split()\n",
    "#     for i in tweet:\n",
    "        \n",
    "\n",
    "# def testa(tweet):\n",
    "#     i = cleanup(tweet).split()\n",
    "#     maior = prop_p_irrel[i]\n",
    "#     if maior < prob_p_rel[i]:\n",
    "#         classificados.append(maior)\n",
    "#     return classificados\n",
    "        \n",
    "# data[\"Resultados Teste\"] = classificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rel = 0\n",
    "fake_rel = 0\n",
    "Irrel = 0\n",
    "fake_irrel = 0\n",
    "\n",
    "n_teste = n-t\n",
    "\n",
    "i = 0\n",
    "while i < len(data['relevancia']):\n",
    "    if data['relevancia'][i] == 'N':\n",
    "        if data['Resultados Teste'][i] == 'N':\n",
    "            N += 1\n",
    "        else:\n",
    "            falso_N += 1\n",
    "        \n",
    "    if data['relevancia'][i] == 'P':\n",
    "        if data['Resultados Teste'][i] == 'P':\n",
    "            P += 1\n",
    "        else:\n",
    "            falso_P += 1\n",
    "            \n",
    "    if data['relevancia'][i] == 'O':\n",
    "        if data['Resultados Teste'][i] == 'O':\n",
    "            O += 1\n",
    "        else:\n",
    "            falso_O += 1\n",
    "    \n",
    "    if data['relevancia'][i] == 'R':\n",
    "        if data['Resultados Teste'][i] == 'R':\n",
    "            R += 1\n",
    "        else:\n",
    "            falso_R += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Porcentagem de verdadeiros positivos (mensagens relevantes e que são classificadas como relevantes)\n",
    "Porcentagem de falsos positivos (mensagens irrelevantes e que são classificadas como relevantes)\n",
    "Porcentagem de verdadeiros negativos (mensagens irrelevantes e que são classificadas como irrelevantes)\n",
    "Porcentagem de falsos negativos (mensagens relevantes e que são classificadas como irrelevantes)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir da comparação entre a classificação feita manualmemte na base de testes e a realizada pelo programa, foi possivel perceber que não houve uma taxa de sucesso razoável. Isto pode ter ocorrido pela baixa quantidade de tweets analisados, que, consequentemente resultaram em um pequeno número de tweets relevantes ao objetivo do projeto, apenas 13% aproximadamente. Portanto não foi possível encontrar um padrão nas palavras usadas pelo clientes analizados por este motivo e pelo fato de muitas palavras serem usados tanto para opniões positivas quanto negativas, como no caso de comparação com outras marcas ou em ironias.\n",
    "\n",
    "Porém seria possível aperfeiçoar o código ao aumentar o número de tweets analizados, evitar retweets e criar mais do que duas classificações. Por exemplo, em ves de relevantes e irrelevantes, poderiamos utilizar positico, negativo e neutro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por que não pode utilizar o próprio classificador para gerar mais amostras de treinamento?\n",
    "\n",
    "Porque o classificador pode ficar \"viciado\", portanto ao fazer isso os seus resultados serão ainsa mais prejudicados.\n",
    "\n",
    "Exemplos de Naïve Bayes: o sistema de spam do email e qualquer outro tipo de previsões como fenômenos climáticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
